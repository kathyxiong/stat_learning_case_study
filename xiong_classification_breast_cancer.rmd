---
title: "Classification Trees and Forests"
author: "Kathy Xiong"
date: "March 26, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(dplyr)
library(rsample)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(mlbench)
library(missForest)
```
```{r}
data("BreastCancer")
head(BreastCancer)
```
```{r}
# drop unused vars
cancer <- select(BreastCancer, -Id)

# complete cases only
sapply(cancer, function(x) {sum(is.na(x))})

cancer <- cancer[!is.na(cancer$Bare.nuclei),]
```
```{r}
# split into training and testing
set.seed(123)
cancer_split <- initial_split(cancer, prop = .8)
cancer_train <- training(cancer_split)
cancer_test  <- testing(cancer_split) 
```

## Classification Tree

```{r}
# default controls
clf_t1 <- rpart(formula = Class ~ .,
                data    = cancer_train,
                method  = "class",
                control = rpart.control(minsplit = 2, 
                                        minbucket = 1,
                                        cp = 0))

plotcp(clf_t1)
```
```{r}
# function to select optimal cp
# from: https://stackoverflow.com/a/52502960
cp.select <- function(big.tree) {
  min.x <- which.min(big.tree$cptable[, 4]) #column 4 is xerror
  for(i in 1:nrow(big.tree$cptable)) {
    if(big.tree$cptable[i, 4] < big.tree$cptable[min.x, 4] + big.tree$cptable[min.x, 5])     return(big.tree$cptable[i, 1]) #column 5: xstd, column 1: cp 
  }
}

# prune tree to optimal cp
cp_best <- cp.select(clf_t1)
clf_t2 <- prune(clf_t1, cp = cp_best)

# print results
print(clf_t2)
```

```{r}
# visualized
rpart.plot(clf_t2)
```
```{r}
# detailed summary
summary(clf_t2)
```
```{r}
# get training and testing errors

# training
pred_train <- predict(clf_t2, cancer_train, type = "class")
conf_train <- confusionMatrix(data = pred_train, reference = cancer_train$Class)

# testing
pred_test <- predict(clf_t2, cancer_test, type = "class")
conf_test <- confusionMatrix(data = pred_test, reference = cancer_test$Class)

# print
print(paste("Training Sensitivity: ", round(conf_train$byClass["Sensitivity"], 2), ",",
            "Specificity: ", round(conf_train$byClass["Specificity"], 2)))

print(paste("Testing Sensitivity: ", round(conf_test$byClass["Sensitivity"], 2), ",",
            "Specificity: ", round(conf_test$byClass["Specificity"], 2)))
```
```{r}
clf_t2$variable.importance # plot it
```

## Random Forest

```{r}
# train a forest with default settings
set.seed(123)

clf_rf1 <- randomForest(
  formula = Class ~ .,
  data    = cancer_train
)

# plot error rate
plot(clf_rf1) # add legend
```
```{r}
# tune RF
oob_errs <- list()
m = ncol(cancer_train) - 1
for (i in 1:m) {
    set.seed(100+i)
    clf_rf <- randomForest(
      formula = Class ~ .,
      data    = cancer_train,
      #n_trees = 100,
      mtry    = i
    )
    oob_errs[[i]] <- (clf_rf$err.rate[,2] + clf_rf$err.rate[,3])/2 # balanced accuracy
}

cols <- colorRampPalette(c("red", "blue"))(m)
for (i in 1:m) {
    if (i == 1) {
        plot(x = 1:500, y = oob_errs[[i]], type = "l", col = cols[i], ylim=c(0,0.1))
    } else {
        lines(x = 1:500, y = oob_errs[[i]], col = cols[i])
    }
    #text(x = 510, y = oob_errs[[i]][500], labels = paste(i), col=cols[i])
    legend("topright", legend=1:m, col=cols, lty=1, cex = 0.5)
}
```
```{r}
# get mtry corresponding to the minimum MSE for a forest with 100 trees
test <- data.frame(oob_errs)
colnames(test) <- NULL
which.min(test[100,])
```

```{r}
# grow optimal forest
clf_rf2 <- randomForest(
  formula = Class ~ .,
  data = cancer_train,
  ntree = 100,
  mtry = 1 
)
```
```{r}
# get training and testing errors

# training
pred_train <- predict(clf_rf2, cancer_train, type = "class")
conf_train <- confusionMatrix(data = pred_train, reference = cancer_train$Class)

# testing
pred_test <- predict(clf_rf2, cancer_test, type = "class")
conf_test <- confusionMatrix(data = pred_test, reference = cancer_test$Class)

# print
print(paste("Training Sensitivity: ", round(conf_train$byClass["Sensitivity"], 2), ",",
            "Specificity: ", round(conf_train$byClass["Specificity"], 2)))

print(paste("Testing Sensitivity: ", round(conf_test$byClass["Sensitivity"], 2), ",",
            "Specificity: ", round(conf_test$byClass["Specificity"], 2)))
```

```{r}
importance(clf_rf2)
varImpPlot(clf_rf2) # plot the other kind of importance?
```

